{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfile_names = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        file_names.append(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-09T16:27:05.794181Z","iopub.execute_input":"2023-12-09T16:27:05.794879Z","iopub.status.idle":"2023-12-09T16:27:06.129665Z","shell.execute_reply.started":"2023-12-09T16:27:05.794849Z","shell.execute_reply":"2023-12-09T16:27:06.128806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import required libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:06.131258Z","iopub.execute_input":"2023-12-09T16:27:06.131704Z","iopub.status.idle":"2023-12-09T16:27:17.858767Z","shell.execute_reply.started":"2023-12-09T16:27:06.131675Z","shell.execute_reply":"2023-12-09T16:27:17.858057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 4243","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:17.859909Z","iopub.execute_input":"2023-12-09T16:27:17.861332Z","iopub.status.idle":"2023-12-09T16:27:17.866707Z","shell.execute_reply.started":"2023-12-09T16:27:17.861296Z","shell.execute_reply":"2023-12-09T16:27:17.865665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_names","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:17.870051Z","iopub.execute_input":"2023-12-09T16:27:17.870587Z","iopub.status.idle":"2023-12-09T16:27:17.959121Z","shell.execute_reply.started":"2023-12-09T16:27:17.870561Z","shell.execute_reply":"2023-12-09T16:27:17.958231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv(file_names[0])\nsample.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:17.960380Z","iopub.execute_input":"2023-12-09T16:27:17.961086Z","iopub.status.idle":"2023-12-09T16:27:18.003830Z","shell.execute_reply.started":"2023-12-09T16:27:17.961056Z","shell.execute_reply":"2023-12-09T16:27:18.002850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(file_names[1])\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.005063Z","iopub.execute_input":"2023-12-09T16:27:18.005369Z","iopub.status.idle":"2023-12-09T16:27:18.053280Z","shell.execute_reply.started":"2023-12-09T16:27:18.005345Z","shell.execute_reply":"2023-12-09T16:27:18.052341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(file_names[2])\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.054637Z","iopub.execute_input":"2023-12-09T16:27:18.054991Z","iopub.status.idle":"2023-12-09T16:27:18.083853Z","shell.execute_reply.started":"2023-12-09T16:27:18.054956Z","shell.execute_reply":"2023-12-09T16:27:18.082446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA of the dataset**","metadata":{}},{"cell_type":"code","source":"# Define  the label\nTARGET = 'target'","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.085255Z","iopub.execute_input":"2023-12-09T16:27:18.085524Z","iopub.status.idle":"2023-12-09T16:27:18.089672Z","shell.execute_reply.started":"2023-12-09T16:27:18.085499Z","shell.execute_reply":"2023-12-09T16:27:18.088364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to plot the null values\ndef plot_null(df):\n    print(\"The number of values in the dataset:\", df.shape[0])\n    sns.heatmap(df.isnull().sum().to_frame(), annot=True, fmt=\"d\", cmap=\"crest\")\n    plt.title(\"Heatmap of the null values\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.091170Z","iopub.execute_input":"2023-12-09T16:27:18.091515Z","iopub.status.idle":"2023-12-09T16:27:18.101285Z","shell.execute_reply.started":"2023-12-09T16:27:18.091488Z","shell.execute_reply":"2023-12-09T16:27:18.100604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Null values in the training dataset\")\nplot_null(train)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.104607Z","iopub.execute_input":"2023-12-09T16:27:18.105169Z","iopub.status.idle":"2023-12-09T16:27:18.374430Z","shell.execute_reply.started":"2023-12-09T16:27:18.105141Z","shell.execute_reply":"2023-12-09T16:27:18.373228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of null values in test data\")\nplot_null(test)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.376654Z","iopub.execute_input":"2023-12-09T16:27:18.377308Z","iopub.status.idle":"2023-12-09T16:27:18.607787Z","shell.execute_reply.started":"2023-12-09T16:27:18.377275Z","shell.execute_reply":"2023-12-09T16:27:18.606898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the null values with string 0\ntrain.fillna(\"0\", inplace=True)\ntest.fillna(\"0\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.608945Z","iopub.execute_input":"2023-12-09T16:27:18.609518Z","iopub.status.idle":"2023-12-09T16:27:18.619076Z","shell.execute_reply.started":"2023-12-09T16:27:18.609488Z","shell.execute_reply":"2023-12-09T16:27:18.617682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the data for null values\nplot_null(train)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.620456Z","iopub.execute_input":"2023-12-09T16:27:18.620726Z","iopub.status.idle":"2023-12-09T16:27:18.895817Z","shell.execute_reply.started":"2023-12-09T16:27:18.620702Z","shell.execute_reply":"2023-12-09T16:27:18.894789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_null(test)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:18.896944Z","iopub.execute_input":"2023-12-09T16:27:18.897198Z","iopub.status.idle":"2023-12-09T16:27:19.140601Z","shell.execute_reply.started":"2023-12-09T16:27:18.897177Z","shell.execute_reply":"2023-12-09T16:27:19.139461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the duplicate values\ntrain[train.duplicated()]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:19.141928Z","iopub.execute_input":"2023-12-09T16:27:19.142611Z","iopub.status.idle":"2023-12-09T16:27:19.167527Z","shell.execute_reply.started":"2023-12-09T16:27:19.142581Z","shell.execute_reply":"2023-12-09T16:27:19.166448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Target Analysis**\nEven though we know this is a binary target variable, no harm in confirming that","metadata":{}},{"cell_type":"code","source":"sns.histplot(x=train[TARGET])\nplt.title(\"Checking the distribution of the target value\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:19.168797Z","iopub.execute_input":"2023-12-09T16:27:19.170486Z","iopub.status.idle":"2023-12-09T16:27:19.410826Z","shell.execute_reply.started":"2023-12-09T16:27:19.170457Z","shell.execute_reply":"2023-12-09T16:27:19.409892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can confirm apart from 0, 1 there is no other data present in the target variable","metadata":{}},{"cell_type":"markdown","source":"# **Feature Analysis**","metadata":{}},{"cell_type":"code","source":"# Group up the training dataframe by \"keyword\" column and \n# count the \"target\" series group values\nkeyword = train.groupby(\"keyword\")[\"target\"].count()\n\n# Convert the above groupby object(Pandas core series) to dataframe\nkeyword_df = pd.DataFrame(data = {\"keyword\": keyword.index, \"count\": keyword.values}).sort_values(by=[\"count\"], ascending=False)\nkeyword_df","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:19.413546Z","iopub.execute_input":"2023-12-09T16:27:19.414010Z","iopub.status.idle":"2023-12-09T16:27:19.428441Z","shell.execute_reply.started":"2023-12-09T16:27:19.413966Z","shell.execute_reply":"2023-12-09T16:27:19.427379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the keyword dataframe\nplt.figure(figsize=(12,5))\n\n# Limit the data to the top 25 keyword\nsns.barplot(data=keyword_df.head(25), x=\"keyword\", y=\"count\")\nplt.xticks(rotation=40)\nplt.ylabel('count')\nplt.title(\"Analysing the top 25 words in the tweet\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:19.429394Z","iopub.execute_input":"2023-12-09T16:27:19.430472Z","iopub.status.idle":"2023-12-09T16:27:19.826290Z","shell.execute_reply.started":"2023-12-09T16:27:19.430423Z","shell.execute_reply":"2023-12-09T16:27:19.825544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group up the training dataframe by \"location\" column and \n# count the \"target\" series group values\nlocation = train.groupby(\"location\")[\"target\"].count()\n\n# Convert the above groupby object(Pandas core series) to dataframe\nlocation_df = pd.DataFrame(data = {\"location\": location.index, \"count\": location.values}).sort_values(by=[\"count\"], ascending=False)\nlocation_df","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:19.827432Z","iopub.execute_input":"2023-12-09T16:27:19.827884Z","iopub.status.idle":"2023-12-09T16:27:19.842843Z","shell.execute_reply.started":"2023-12-09T16:27:19.827859Z","shell.execute_reply":"2023-12-09T16:27:19.842198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the keyword dataframe\nplt.figure(figsize=(12,5))\n\n# Limit the data to the top 25 keyword\nsns.barplot(data=location_df.head(25), x=\"location\", y=\"count\")\nplt.xticks(rotation=40)\nplt.ylabel('count')\nplt.title(\"Analysing the top 25 locations in the tweet\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:19.843993Z","iopub.execute_input":"2023-12-09T16:27:19.844418Z","iopub.status.idle":"2023-12-09T16:27:20.234445Z","shell.execute_reply.started":"2023-12-09T16:27:19.844395Z","shell.execute_reply":"2023-12-09T16:27:20.233798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the keyword dataframe\nplt.figure(figsize=(12,5))\n\n# Limit the data to the top 25 keyword and discard the first value\nsns.barplot(data=location_df.head(25).iloc[1:,:], x=\"location\", y=\"count\")\nplt.xticks(rotation=40)\nplt.ylabel('count')\nplt.title(\"Analysing the top 25 locations in the tweet\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.235640Z","iopub.execute_input":"2023-12-09T16:27:20.236125Z","iopub.status.idle":"2023-12-09T16:27:20.610778Z","shell.execute_reply.started":"2023-12-09T16:27:20.236098Z","shell.execute_reply":"2023-12-09T16:27:20.609752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the functions to get the maximum number of words in each column\ndef get_max_length_sentence(df, key):\n    max_length = 0\n    for text in df[key]:\n        if len(text) > max_length:\n            max_length = len(text)\n    print(f\"maximum length of the {key} column is: {max_length}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.611958Z","iopub.execute_input":"2023-12-09T16:27:20.612253Z","iopub.status.idle":"2023-12-09T16:27:20.618098Z","shell.execute_reply.started":"2023-12-09T16:27:20.612227Z","shell.execute_reply":"2023-12-09T16:27:20.616814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Maximum lengths of the columns in train dataset\nget_max_length_sentence(train, \"text\")\nget_max_length_sentence(train, \"keyword\")\nget_max_length_sentence(train, \"location\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.620075Z","iopub.execute_input":"2023-12-09T16:27:20.620433Z","iopub.status.idle":"2023-12-09T16:27:20.638482Z","shell.execute_reply.started":"2023-12-09T16:27:20.620406Z","shell.execute_reply":"2023-12-09T16:27:20.635992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Maximum lengths of the columns in test dataset\nget_max_length_sentence(test, \"text\")\nget_max_length_sentence(test, \"keyword\")\nget_max_length_sentence(test, \"location\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.642476Z","iopub.execute_input":"2023-12-09T16:27:20.643478Z","iopub.status.idle":"2023-12-09T16:27:20.657505Z","shell.execute_reply.started":"2023-12-09T16:27:20.643444Z","shell.execute_reply":"2023-12-09T16:27:20.656239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.659098Z","iopub.execute_input":"2023-12-09T16:27:20.659523Z","iopub.status.idle":"2023-12-09T16:27:20.673864Z","shell.execute_reply.started":"2023-12-09T16:27:20.659489Z","shell.execute_reply":"2023-12-09T16:27:20.672601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.pop(\"id\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.675088Z","iopub.execute_input":"2023-12-09T16:27:20.675324Z","iopub.status.idle":"2023-12-09T16:27:20.683195Z","shell.execute_reply.started":"2023-12-09T16:27:20.675302Z","shell.execute_reply":"2023-12-09T16:27:20.681698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.684333Z","iopub.execute_input":"2023-12-09T16:27:20.684601Z","iopub.status.idle":"2023-12-09T16:27:20.697415Z","shell.execute_reply.started":"2023-12-09T16:27:20.684577Z","shell.execute_reply":"2023-12-09T16:27:20.696593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.701821Z","iopub.execute_input":"2023-12-09T16:27:20.702074Z","iopub.status.idle":"2023-12-09T16:27:20.709994Z","shell.execute_reply.started":"2023-12-09T16:27:20.702053Z","shell.execute_reply":"2023-12-09T16:27:20.709004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle the dataframe\ntrain = shuffle(train, random_state=SEED)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.711478Z","iopub.execute_input":"2023-12-09T16:27:20.712032Z","iopub.status.idle":"2023-12-09T16:27:20.727674Z","shell.execute_reply.started":"2023-12-09T16:27:20.712001Z","shell.execute_reply":"2023-12-09T16:27:20.726767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 32\n\n# convert the train data to tf.data.Dataset object\ntrain_tf = tf.data.Dataset.from_tensor_slices((train[\"keyword\"]+train[\"location\"]+train[\"text\"], train[\"target\"]))\n\n# Convertt it into batch\ntrain_tf = train_tf.shuffle(int((SEED*13)/8)).batch(BATCH)\n\n# convert the test data to tf.data.Dataset object\ntest_tf = tf.data.Dataset.from_tensor_slices(test[\"keyword\"]+test[\"location\"]+test[\"text\"])\n\n# Convertt it into batch\ntest_tf = test_tf.batch(BATCH)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.728666Z","iopub.execute_input":"2023-12-09T16:27:20.729058Z","iopub.status.idle":"2023-12-09T16:27:20.822510Z","shell.execute_reply.started":"2023-12-09T16:27:20.729025Z","shell.execute_reply":"2023-12-09T16:27:20.821051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Text Vectorization**\nTo enable the model to process the text data, we need to convert it into integer values throguh a process called text vectorization.","metadata":{}},{"cell_type":"code","source":"max_length = 165\nmax_tokens = 20_000\n\n# Instantiate the text vectorization layer\ntext_vect = layers.TextVectorization(max_tokens=max_tokens,output_mode='int', output_sequence_length=max_length)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.824022Z","iopub.execute_input":"2023-12-09T16:27:20.824414Z","iopub.status.idle":"2023-12-09T16:27:20.861837Z","shell.execute_reply.started":"2023-12-09T16:27:20.824380Z","shell.execute_reply":"2023-12-09T16:27:20.860871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learn the vocabulary\ntext_vect.adapt(train_tf.map(lambda twt, target: twt))","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:20.863071Z","iopub.execute_input":"2023-12-09T16:27:20.864071Z","iopub.status.idle":"2023-12-09T16:27:21.653839Z","shell.execute_reply.started":"2023-12-09T16:27:20.864040Z","shell.execute_reply":"2023-12-09T16:27:21.653080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the vocabulary\nvocab = text_vect.get_vocabulary()\nprint(\"Size of the vocabulary= \",len(vocab))\nvocab = np.array(vocab)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.655110Z","iopub.execute_input":"2023-12-09T16:27:21.656339Z","iopub.status.idle":"2023-12-09T16:27:21.711066Z","shell.execute_reply.started":"2023-12-09T16:27:21.656306Z","shell.execute_reply":"2023-12-09T16:27:21.709823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vectorize the training dataset\ntrain_tf = train_tf.map(lambda twt, target:(text_vect(twt), target), num_parallel_calls=tf.data.AUTOTUNE)\n\n# Vectorize the etsting dataset\ntest_tf = test_tf.map(lambda twt:text_vect(twt), num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.712294Z","iopub.execute_input":"2023-12-09T16:27:21.712650Z","iopub.status.idle":"2023-12-09T16:27:21.819840Z","shell.execute_reply.started":"2023-12-09T16:27:21.712619Z","shell.execute_reply":"2023-12-09T16:27:21.818876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to print the tokenized data\ndef print_sample(data):\n    for sample, target in data:\n        #Print the first item\n        print(\"1st sample:\",sample[0].numpy())\n        print(\"\\n\")\n        #Print the second item\n        print(\"2nd sample:\",sample[1].numpy())\n        print(\"\\n\")\n        #Print the third item\n        print(\"3rd sample:\",sample[2].numpy())\n        print(\"\\n\")\n        break","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.821257Z","iopub.execute_input":"2023-12-09T16:27:21.821509Z","iopub.status.idle":"2023-12-09T16:27:21.828912Z","shell.execute_reply.started":"2023-12-09T16:27:21.821488Z","shell.execute_reply":"2023-12-09T16:27:21.827593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_sample(train_tf)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.830491Z","iopub.execute_input":"2023-12-09T16:27:21.830865Z","iopub.status.idle":"2023-12-09T16:27:21.897180Z","shell.execute_reply.started":"2023-12-09T16:27:21.830837Z","shell.execute_reply":"2023-12-09T16:27:21.895987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the vectorized tweet and the decoded tweet\nfor tx in train_tf:\n    print(\"\\t\\t\\t\\tVectorized Tweet:\\n\",tx[0][0])\n    print(\"\\n\\n\\t\\t\\t\\tDecoded Tweet:\\n\", \" \".join(vocab[tx[0][0].numpy()]))\n    break","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.898780Z","iopub.execute_input":"2023-12-09T16:27:21.899094Z","iopub.status.idle":"2023-12-09T16:27:21.925556Z","shell.execute_reply.started":"2023-12-09T16:27:21.899065Z","shell.execute_reply":"2023-12-09T16:27:21.924700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model**\nTo classify the tweets, we will employ a Transformer model specifically designed as an Encoder-only model. In this approach, we will define the Encoder layer and incorporate a Positional Embedding layer using Keras subclassing. By utilizing these components, we aim to enhance the accuracy and effectiveness of our classification model.\n\nMoreover, the Transformer model's architecture enables it to capture contextual relationships and dependencies among words or tokens within the tweets. The Encoder layer acts as a powerful feature extractor, learning representations that contribute to the tweet classification task.\n\nAdditionally, the Positional Embedding layer adds crucial positional information to the input tokens, enabling the model to discern the sequential order of words in the tweet. This positional encoding facilitates the Transformer model in capturing long-range dependencies and effectively processing the input text.\n\nBy combining the Transformer's robust architecture with Keras subclassing, we can create a powerful and flexible model that yields accurate tweet classification results.","metadata":{}},{"cell_type":"code","source":"#Define a Transformer Encoder using subclassed layer\nclass TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        #Size of the input vector (size of the vocabulary)\n        self.embed_dim = embed_dim\n        #Size of the inner dense layer\n        self.dense_dim = dense_dim\n        #Number of attention heads\n        self.num_heads = num_heads\n\n        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.dense_proj = keras.Sequential(\n                   [layers.Dense(dense_dim, activation=\"relu\"),\n                    layers.Dense(embed_dim),]\n                                        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.max_pool1 = layers.GlobalMaxPooling1D()\n\n    #Define a call() method  where forward pass is implemented\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            mask = mask[:, tf.newaxis, :]\n\n        #Apply the attention layer\n        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n        #Normalize the data\n        proj_input = self.layernorm_1(inputs + attention_output)\n        #Apply the dense layer\n        proj_output = self.dense_proj(proj_input)\n        #Normalize the data and return it\n        return self.layernorm_2(proj_input + proj_output)\n        \n        #return self.max_pool1(norm)\n\n    #Define configuration method\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n                    \"embed_dim\": self.embed_dim,\n                    \"num_heads\": self.num_heads,\n                    \"dense_dim\": self.dense_dim,\n                    })\n        return config","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.926919Z","iopub.execute_input":"2023-12-09T16:27:21.927424Z","iopub.status.idle":"2023-12-09T16:27:21.936702Z","shell.execute_reply.started":"2023-12-09T16:27:21.927393Z","shell.execute_reply":"2023-12-09T16:27:21.935711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implementing positional embedding as a subclassed layer\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.sequence_length = sequence_length\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.token_embeddings = layers.Embedding(\n          input_dim=input_dim, output_dim=output_dim)\n        self.position_embeddings = layers.Embedding(\n                   input_dim=sequence_length, output_dim=output_dim)\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n            return tf.math.not_equal(inputs, 0)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n           \"output_dim\": self.output_dim,\n           \"sequence_length\": self.sequence_length,\n           \"input_dim\": self.input_dim,\n                    })\n        return config","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.937782Z","iopub.execute_input":"2023-12-09T16:27:21.937996Z","iopub.status.idle":"2023-12-09T16:27:21.951390Z","shell.execute_reply.started":"2023-12-09T16:27:21.937976Z","shell.execute_reply":"2023-12-09T16:27:21.950419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Construct the model\n\n#Define the input\ninputs = keras.Input(shape=(None,), dtype=\"int64\")\n\n#Apply positional embeddings\npos_embed = PositionalEmbedding(sequence_length=165,\n                        input_dim=20_000,\n                        output_dim=256)(inputs)\n\n#Apply the encoder\nencoded = TransformerEncoder(embed_dim=256,\n                             dense_dim=32,\n                             num_heads=8)(pos_embed)\n\n\nx = layers.GlobalMaxPooling1D()(encoded)\nx = layers.Dropout(0.5)(x)\noutput = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\nmodel = keras.Model(inputs=inputs,outputs=output)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:27:21.952364Z","iopub.execute_input":"2023-12-09T16:27:21.953027Z","iopub.status.idle":"2023-12-09T16:27:22.347665Z","shell.execute_reply.started":"2023-12-09T16:27:21.952998Z","shell.execute_reply":"2023-12-09T16:27:22.346441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n             loss=tf.keras.losses.BinaryCrossentropy(),\n             metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:31:05.511717Z","iopub.execute_input":"2023-12-09T16:31:05.512052Z","iopub.status.idle":"2023-12-09T16:31:05.529851Z","shell.execute_reply.started":"2023-12-09T16:31:05.512025Z","shell.execute_reply":"2023-12-09T16:31:05.529144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:31:18.315127Z","iopub.execute_input":"2023-12-09T16:31:18.315510Z","iopub.status.idle":"2023-12-09T16:31:18.346230Z","shell.execute_reply.started":"2023-12-09T16:31:18.315480Z","shell.execute_reply":"2023-12-09T16:31:18.345226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model=model,\n                      to_file=\"model.png\",\n                      show_shapes=True,\n                      show_layer_names=True,\n                      expand_nested=True,\n                      show_layer_activations=True,\n                      show_trainable=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:33:36.605225Z","iopub.execute_input":"2023-12-09T16:33:36.605576Z","iopub.status.idle":"2023-12-09T16:33:36.847176Z","shell.execute_reply.started":"2023-12-09T16:33:36.605549Z","shell.execute_reply":"2023-12-09T16:33:36.845908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the callbacks\ncallbacks = [keras.callbacks.ModelCheckpoint(\"tweet_classifier.tf\", save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:46:11.962457Z","iopub.execute_input":"2023-12-09T16:46:11.962855Z","iopub.status.idle":"2023-12-09T16:46:11.968396Z","shell.execute_reply.started":"2023-12-09T16:46:11.962825Z","shell.execute_reply":"2023-12-09T16:46:11.966896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the validation data size\nval_size = int(0.25*len(train_tf))","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:35:32.712807Z","iopub.execute_input":"2023-12-09T16:35:32.713176Z","iopub.status.idle":"2023-12-09T16:35:32.717880Z","shell.execute_reply.started":"2023-12-09T16:35:32.713141Z","shell.execute_reply":"2023-12-09T16:35:32.717097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into training and validaation\nval_data = train_tf.take(val_size)\ntrain_data = train_tf.skip(val_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:36:43.641003Z","iopub.execute_input":"2023-12-09T16:36:43.641328Z","iopub.status.idle":"2023-12-09T16:36:43.653828Z","shell.execute_reply.started":"2023-12-09T16:36:43.641303Z","shell.execute_reply":"2023-12-09T16:36:43.653027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\nhistory = model.fit(train_data,\n                    epochs=150,\n                    validation_data=val_data,\n                    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T16:46:16.089697Z","iopub.execute_input":"2023-12-09T16:46:16.090130Z","iopub.status.idle":"2023-12-10T01:08:32.291928Z","shell.execute_reply.started":"2023-12-09T16:46:16.090071Z","shell.execute_reply":"2023-12-10T01:08:32.291272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation loss\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, \"bo\", label=\"Training loss\")\nplt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\nplt.title(\"Training and validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:38:30.066981Z","iopub.execute_input":"2023-12-10T01:38:30.067286Z","iopub.status.idle":"2023-12-10T01:38:30.311247Z","shell.execute_reply.started":"2023-12-10T01:38:30.067264Z","shell.execute_reply":"2023-12-10T01:38:30.309963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation accuracy\nacc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nplt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\nplt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\nplt.title(\"Training and validation accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:08.020265Z","iopub.execute_input":"2023-12-10T01:39:08.020594Z","iopub.status.idle":"2023-12-10T01:39:08.258944Z","shell.execute_reply.started":"2023-12-10T01:39:08.020567Z","shell.execute_reply":"2023-12-10T01:39:08.257808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Classify the tweets of test data\npredictions = model.predict(test_tf)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:39:22.896061Z","iopub.execute_input":"2023-12-10T01:39:22.896403Z","iopub.status.idle":"2023-12-10T01:39:59.287728Z","shell.execute_reply.started":"2023-12-10T01:39:22.896377Z","shell.execute_reply":"2023-12-10T01:39:59.287030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the predictions\npredictions","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:40:23.426968Z","iopub.execute_input":"2023-12-10T01:40:23.427319Z","iopub.status.idle":"2023-12-10T01:40:23.434705Z","shell.execute_reply.started":"2023-12-10T01:40:23.427291Z","shell.execute_reply":"2023-12-10T01:40:23.433699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.5\n#Convert the float values to binary\nfinal_predictions = [1 if i > threshold else 0 for i in predictions]\nfinal_predictions[:10]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:40:36.219679Z","iopub.execute_input":"2023-12-10T01:40:36.220055Z","iopub.status.idle":"2023-12-10T01:40:36.230641Z","shell.execute_reply.started":"2023-12-10T01:40:36.220028Z","shell.execute_reply":"2023-12-10T01:40:36.230073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:40:49.420477Z","iopub.execute_input":"2023-12-10T01:40:49.420824Z","iopub.status.idle":"2023-12-10T01:40:49.430283Z","shell.execute_reply.started":"2023-12-10T01:40:49.420798Z","shell.execute_reply":"2023-12-10T01:40:49.429468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions = pd.DataFrame(columns=[\"id\",\"target\"])\nsubmissions[\"target\"] = final_predictions\nsubmissions[\"id\"] = test.id\nsubmissions","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:41:05.248149Z","iopub.execute_input":"2023-12-10T01:41:05.248468Z","iopub.status.idle":"2023-12-10T01:41:05.262891Z","shell.execute_reply.started":"2023-12-10T01:41:05.248443Z","shell.execute_reply":"2023-12-10T01:41:05.261829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Save the file as a csv file\nsubmissions.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:41:21.094306Z","iopub.execute_input":"2023-12-10T01:41:21.094621Z","iopub.status.idle":"2023-12-10T01:41:21.104667Z","shell.execute_reply.started":"2023-12-10T01:41:21.094595Z","shell.execute_reply":"2023-12-10T01:41:21.103785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}